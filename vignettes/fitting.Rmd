---
title: "Fitting and analysing models"
author: Silvaneo V. dos Santos Jr.
output: rmdformats::readthedown
date: "`r Sys.setlocale('LC_TIME', 'English'); format(Sys.Date(),'%d of %B, %Y')`"
bibliography: '`r system.file("REFERENCES.bib", package="kDGLM")`'
link-citations: TRUE
urlcolor: blue
linkcolor: green
vignette: >
  %\VignetteIndexEntry{Fitting and analysing models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = ""
)

library(kDGLM)
# devtools::load_all()
```

# Table of contents

<ol>
<li><details><summary>[Introduction:](intro.html) ></summary>
  <ul>
  <li>[Introduction](intro.html#introduction)
  <li>[Notation](intro.html#notation)
  </ul></details>
  </li>
<li><details><summary>[Creating the model structure:](structures.html) ></summary>
  <ul>
  <li>[A structure for polynomial trend models](structures.html#a-structure-for-polynomial-trend-models)
  <li>[A structure for dynamic regression models](structures.html#a-structure-for-dynamic-regression-models)
  <li>[A structure for harmonic trend models](structures.html#a-structure-for-harmonic-trend-models)
  <li>[A structure for autoregresive models](structures.html#a-structure-for-autoregresive-models)
  <li>[A structure for overdispersed models](structures.html#a-structure-for-overdispersed-models)
  <li>[Handling multiple structural blocks](structures.html#handling-multiple-structural-blocks)
  <li>[Handling multiple linear predictors](structures.html#handling-multiple-linear-predictors)
  <li>[Handling unknown components in the planning matrix $F_t$](structures.html#handling-unknown-components-in-the-planning-matrix-f_t)
  <li>[Special priors](structures.html#special-priors)
  </ul></details>
  </li>  
  
<li><details><summary>[Creating the model outcome:](outcomes.html) > </summary>
  <ul>
  <li>[Normal case](outcomes.html#normal-case)
  <li>[Poisson case](outcomes.html#poisson-case)
  <li>[Gamma case](outcomes.html#gamma-case)
  <li>[Multinomial case](outcomes.html#multinomial-case)
  <li>[Handling multiple outcomes](outcomes.html#handling-multiple-outcomes)
  </ul></details>
  </li>
<li><details><summary>[Fitting and analysing models:](fitting.html) > </summary>
  <ul>
  <li>[Filtering and smoothing](fitting.html#filtering-and-smoothing)
  <li>[Extracting components](fitting.html#extracting-components)
  <li>[Forecasting](fitting.html#forecasting)
  <li>[Intervention and monitoring](fitting.html#intervention-and-monitoring)
  <li>[Tools for sensibility analysis](fitting.html#tools-for-sensibility-analysis)
  <li>[Sampling and hyper parameter estimation](fitting.html#sampling-and-hyper-parameter-estimation)
  </ul></details>
  </li>
<li><details><summary>Advanced examples:> </summary><ul>
  <li>[Space-time model hospital admissions from gastroenteritis](example1.html)
  </details>
</ul></li>
</ol>

# Introduction

In this section we briefly present the usage of the `fit_model` function, along side the auxiliary functions for analyzing a fitted model, such as the `summary`, `coef`,`plot` and `forecast` methods, the `plot_lat_var`, `plot_lin_pred` and `dlm_sampling` functions. For a deep dive in the details of each argument of each function, see the documentation of those function and/or the reference manual.

# Filtering and smoothing
 
The usage of the `fit_model` function is as follows:

```{r echo=TRUE, eval=FALSE}
fit_model(
  ...,
  smooth = TRUE,
  p_monit = NA
)
```

The `...` argument receives `dlm_block` and `dlm_distr` objects, whose creation was described in the previous sections. In particular, if the user gives a `dlm_distr` object as a named argument, its name is used as the label for that outcome.

`smooth` is a boolean indicating if the smoothed distribution of the latent variables should be evaluated (generally we recommend the users to not change this value, as the computational cost of smoothing is almost always negligible).

`p_monit` controls the sensibility of the automated monitoring and we shall discuss its usage later on this section.

Bellow we present the code for a Poisson model:

```{r}
level <- polynomial_block(rate = 1, order = 2, D = 0.95)
season <- harmonic_block(rate = 1, period = 12, order = 2, D = 0.975)

outcome <- Poisson(lambda = "rate", data = c(AirPassengers))

fitted.data <- fit_model(
  level, season, # Strucuture
  AirPassengers = outcome # oucome
)
```


The first two lines create structural blocks representing a random walk on $\mu_t$ and a seasonal component described by harmonics. The fourth line creates a Poisson outcome such that the rate parameter `lambda` is equal to $\exp\{\text{rate}\}$, since that was the name given to the linear predictor when creating the structural blocks (for details about the linear predictor see the previous section). The last few lines receive the model structure and the Poisson outcome and fits the model, obtaining the parameters for the filtered and smoothed distribution of all latent states.

The user can see how the model fits the data using the `plot` method, whose syntax is as follows:

```{r echo=TRUE, eval=FALSE}
plot.fitted_dlm(
  model,
  pred.cred = 0.95,
  lag = 1,
  cutoff = floor(model$t / 10),
  plot.pkg = "auto"
)
```

The `model` argument must be a `fitted_dlm` object (i.e., the output of the `fit_model` function). 

`pred.cred` must be a number between $0$ and $1$ representing the desired credibility of the predictions.

`lag` must be an integer representing the number of steps ahead to be used for predictions. If `lag`$<0$, the smoothed distribution is used for predictions and, if `lag`$=0$, the filtered distribution is used.

`cutoff` must be an integer representing the number of initial steps that should be skipped in the plot. Usually, the model is still learning in the initial steps, so the predictions are not reliable. The default value is one tenth of the sample size rounded down.

Lastly `plot.pkg` must be a string specifing the plot engine to be used. Should be one of `'auto'`, `'base'`, `'ggplot2'` or `'plotly'`. If `'auto'` is used, then the package will try to use `plotly`, if it fails, then it tries to use `ggplot2` and, if it also fails, then the package will use the native functions provided by `R`.


```{r, results='hide'}
plot(fitted.data, plot.pkg = "base")
```

For the sake of brevity, we will not detail the usage of the remaining functions presented in this subsection, since they have similar syntax to the `plot` method method of the `fitted_dlm` class. We strongly advise the user to consult the reference manual of this package and the documentation of each function for detailed descriptions of any function. 

To see a summary of the fitted model, one can use the `summary` method:


```{r}
summary(fitted.data)
```

Notice that the coefficients shown are those of the last observation, but one can also see the summary of any particular time by changing the `t` argument:

```{r}
summary(fitted.data, t = 100)
```

For more details about the usage of the `summary` method of the `fitted_dlm` class, see the associated documentation (`help(summary.fitted_dlm)`).

# Extracting components

Naturally, the user may want to extract information about the posterior distribution of the parameters of the fitted model, such that a more thorough analysis may be performed. For extracting the parameters of the distribution of latent states, linear predictors and observational model parameters, one can use the `coef` method:

```{r echo=TRUE}
fitted.coef <- coef(fitted.data)
```

The output of this function is a `dlm_coef` object containing:

 - `data`: A data frame with the model evaluated at each observed time.

 - `mt`: A $n \times T$ matrix representing the mean of the latent variables at each time, where $n$ is the number of latent variables in the model and $T$ is the length of the time series;

 - `Ct`: A 3D-array containing the covariance matrix of the latent variable at each time. Dimensions are $n \times n \times T$;

 - `ft`: A $k \times T$ matrix representing the mean of the linear predictor at each time, where $k$ is the number of linear predictors in the model and $T$ is the length of the time series;

 - `Qt`: A 3D-array containing the covariance matrix for the linear predictor at each time. Dimensions are $k \times k \times T$;

 - Several vectors with some metrics, including the **Mean Absolute Error** (MAE), the **Mean Absolute Scaled Error** (MASE), the **Relative Absolute Error** (RAE), the **Mean Squared Error** (MSE) and the **Interval Score** (interval.score).

 - `conj.param`: A list containing the conjugated parameters for the distribution of the parameter of the observational model.

It is important to highlight that, following the method proposed in @ArtigokParametrico, the joint distribution of the latent states (and the linear predictor) at each time is Gaussian, such that the mean vector and covariance matrix completely define their joint distribution.

The user may also want to plot the latent variables, for which the `plot` method for the `dlm_coef` class can be used:

```{r echo=TRUE}
plot(fitted.coef, plot.pkg = "base")
```

If the user wants to see only a restricted set of latent variables, the extra argument `var` can be used to specify the name of the variable to plot:

```{r echo=TRUE}
plot(fitted.coef, "Var.Poly.Level", plot.pkg = "base")
```

The user may also plot the linear predictors, by specifying the name of the linear predictor:

```{r echo=TRUE}
plot(fitted.coef, "rate", plot.pkg = "base")
```

Lastly, although we do not recommend it, the user may also extract some of these information directly from the `fitted_dlm` object.

We strongly recommend every user to consult the documentation of each of these functions to see the full set of features provided by the package.

# Forecasting

Notice that all methods and functions presented until now were restricted to the period where the model was fitted. If the user wishes make predictions for future observations, the `forecast` method can be used:

```{r echo=TRUE}
forecast(fitted.data, 20, plot = "base")$plot
```

Additionally, the `forecast` method for the `fitted_dlm` class also provides a similar set of attributes of that which the `dlm_coef` class has, specifically, the predictive distribution for the latent states, the linear predictors and the observational model parameters, along with the predictions for future observations.

It is relevant to point out that if external data is necessary for forecasting, such as for models with regressive blocks or transfer functions, it is necessary to pass those values for the `forecast` method. In this scenario, the user must pass a new argument named as the variable that is "missing" from the model. See the documentation to see how to determine the name of the missing values or, more practically, try to use the `forecast` method without the necessary arguments, since the name of the missing variables will be presented in the error message.

For more details on the usage of this function, see the associated documentation (`help(forecast.fitted_dlm)`).

# Updating a fitted model

One of the major advantages of the sequential nature of the methodology proposed in @ArtigokParametrico is that it allows for the updating of the posterior distribution of the parameter when new data arrives, but without the necessity of reprocessing the data previously observed. This feature is particularly useful in problems that involve monitoring or real time inference about a phenomena.

For updating a `fitted_dlm` object, the user can use the `update` method for the `fitted_dlm` class:

```{r echo=TRUE,eval=FALSE}
update.fitted_dlm(model, ...)
```

As one can imagine, the `model` argument must be a `fitted_dlm` object. Moreover, the `...` argument must be a sequence of named arguments containing the new information observed. For example:

```{r echo=TRUE}
level <- polynomial_block(rate = 1, order = 2, D = 0.95)
season <- harmonic_block(rate = 1, period = 12, order = 2, D = 0.975)
# Omitting the last 44 observations
outcome <- Poisson(lambda = "rate", data = c(AirPassengers)[1:100])
fitted.data <- fit_model(
  level, season, # Strucuture
  AirPassengers = outcome
) # outcome
updated.fit <- update(fitted.data,
  AirPassengers = list(data = c(AirPassengers)[101:144])
)
```

The `update` function may require extra arguments containing covariates, pulses (for the transfer function), the offset, etc.. In such cases, the syntax is the same as the `forecast` method.
 
# Intervention and monitoring

As a key feature, the package has support for intervention and automated monitoring. First, if the user is aware that at some specific time there is some change in the time series that is not part of its temporal dynamic, then the user should provide that information in the model structure. For that we provide the `intervention` function:

```{r echo=TRUE}
data <- c(AirPassengers)
# Adding an artificial change, so that we can make an intervention on the data at that point
# Obviously, one should NOT change their own data.
data[60:144] <- data[60:144] + 100

level <- polynomial_block(rate = 1, order = 2, D = 0.95)
season <- harmonic_block(rate = 1, order = 2, period = 12, D = 0.975)

# Reducing the discount factor so that the model can capture the expected change.
level <- level |> intervention(time = 60, D = 0.005, var.index = 1)
# Comment the line above to see the fit without the intervention

fitted.data <- fit_model(level, season,
  AirPassengers = Poisson(lambda = "rate", data = data)
)

plot(fitted.data, plot.pkg = "base")
```

See the documentation of the `intervention` function for more details about its arguments. Also, we strongly recommend the user to consult @WestHarr-DLM, chapter 11 for a detailed discussion about Feed-Foward Interventions.

In case the user is not aware of any behavioral changes in the data, but suspects that they may have occurred at some unknown time, then we recommend the use of automated monitoring.

To fit a model using automated monitoring, the user must provide a valid value for the `p.monit` argument in the `fit_model` function. This argument receives values between $0$ and $1$, such that its value is interpreted as the prior probability (i.e., the probability before observing the data), at any given time, of behavioral change in the series that is not accommodated by the temporal dynamic.

```{r echo=TRUE}
data <- c(AirPassengers)
# Adding an artificial change, so that we can make an intervention on the data at that point
# Obviously, one should NOT change their own data.
data[60:144] <- data[60:144] + 100

level <- polynomial_block(rate = 1, order = 2, D = 0.95)
season <- harmonic_block(rate = 1, order = 2, period = 12, D = 0.975)

fitted.data <- fit_model(level, season,
  AirPassengers = Poisson(lambda = "rate", data = data),
  p.monit = 0.05
)

plot(fitted.data, plot.pkg = "base")
```

The approach used for automated monitoring is almost identical to that of @WestHarr-DLM, chapter 11.4, using Bayes' factor, such that `p.monit`$=0.05$ yields a threshold equivalent to that recommended in @WestHarr-DLM.

# Tools for sensibility analysis

In some situations, the user may not be sure about which value to use for some hyperparameter of the model (such as the discount factor or the order of a block) or about the inclusion of some structural block. As such, one might choose to perform a sensibility analysis on the effect of those choices. For such analysis, we provide the `search_model` function.

As an motivational example, let us assume that we are unsure about which value to choose for the discount factor in a polynomial trend block of a Poisson model. First, when defining the model structure, we must set the discount factor as a string, which will be used as the label for the unspecified parameter:

```{r echo=TRUE}
level <- polynomial_block(rate = 1, order = 2, D = "D1")
```

By setting the discount factor as a string, the structural block becomes partially **undefined**:

```{r echo=TRUE}
summary(level)
```


As such, this block **can not* be used in the `fit_model` function:

```{r echo=TRUE, error=TRUE}
season <- harmonic_block(rate = 1, order = 2, period = 12, D = 0.975)
outcome <- Poisson(lambda = "rate", data = c(AirPassengers))
fitted.data <- fit_model(level, season, AirPassengers = outcome)
```

As the user can see in the error message above, an undefined `dlm_block` can only be used with the `search_model` function. This function is used to fit a set of models, while computing some comparative metrics.

```{r echo=TRUE, eval=FALSE}
search_model(..., search.grid,
  condition = "TRUE",
  metric = "log.like", smooth = TRUE, lag = 1,
  pred.cred = 0.95, metric.cutoff = NA,
  p.monit = NA
)
```


The usage of the `search_model` function is almost identical to that of the `fit_model` function, the `...`, `smooth` and `p.monit` arguments having the exact same meaning.

The `search.grid` argument must be a list containing, for each undefined parameter, the list of values to be tested. By default, this function will test all possible combinations of the undefined parameter. If the user wishes to skip some combinations, the `condition` argument can be used to provide a string with the criterion to determine which combinations shall be evaluated.

The remaining options provide some control over the comparative metrics. The `metric` argument (`'mae'`, `'mase'`, `'rae'`, `'log.like'` or `'interval.score'`) indicates which metric to use when selecting the best model (all metrics are calculated, not matter the value of the `metric` argument, but only the best model by the chosen metric is saved). The `lag` argument indicates the number of steps ahead to be used for predictions ($0$ indicates filtered predictions and negative values indicate smoothed predictions). The `pred.cred` argument indicates the credibility of the intervals used when computing the Interval Score. The `metric.cutoff` argument indicates the number of initial observations to be ignored when computing the metrics.

After evaluating all valid combinations of hyper parameters, the `search_model` function returns the best model by the chosen metric, along with a data frame containing the metrics for each model evaluated.

```{r echo=TRUE, eval=FALSE}
level <- polynomial_block(rate = 1, order = 2, D = "D.level")
season <- harmonic_block(
  rate = "sazo.effect", period = 12,
  order = 2, D = "D.sazo"
)

outcome <- Poisson(lambda = "rate", data = c(AirPassengers))

search_model(level, season, outcome,
  search.grid = list(
    sazo.effect = c(0, 1),
    D.level = seq(0.8, 1, l = 11),
    D.sazo = seq(0.95, 1, l = 11)
  ),
  condition = "sazo.effect==1 | D.sazo==1"
)
```


It is important to note that not all hyper parameters can be tested directly by the search model function, indeed, only the components associated with $F_t$, $D_t$, $h_t$, $H_t$, $a_1$ and $R_1$ can be treated as undefined. Still, if the user wants to test some other hyper parameter that cannot be tested directly (such as the order of a polynomial block or the period of a harmonic block), he can create one block for each option and perform a sensibility analysis for the inclusion/exclusion of each block:

```{r echo=TRUE, eval=FALSE}
# Creating a block for each order
level <- polynomial_block(rate = "pol.ord.1", order = 1, D = 0.95) +
  polynomial_block(rate = "pol.ord.2", order = 2, D = 0.95) +
  polynomial_block(rate = "pol.ord.3", order = 3, D = 0.95) +
  polynomial_block(rate = "pol.ord.4", order = 4, D = 0.95)
season <- harmonic_block(rate = 1, order = 2, period = 12, D = 0.975)

outcome <- Poisson(lambda = "rate", data = c(AirPassengers))

search_model(level, season, outcome,
  search.grid = list(
    # Each block can be present (1) or absent (0).
    pol.ord.1 = c(0, 1), pol.ord.2 = c(0, 1),
    pol.ord.3 = c(0, 1), pol.ord.4 = c(0, 1)
  ),
  condition = "pol.ord.1+pol.ord.2+pol.ord.3+pol.ord.4==1"
  # Only test combinations with exactly one polynomial block.
)
```


# Sampling and hyper parameter estimation

Lastly, one may also want to draw samples from the latent states, linear predictors and/or the parameters $\eta_t$ of the observational model. This can be useful to evaluate non-linear functions of the model parameters or when the DGLM is only a part of a bigger model, from which the parameters are being estimated with Gibbs Algorithm. It is important to note that, with the method proposed in @ArtigokParametrico, sampling from the posterior distribution of the latent states is straight forward, allowing the user to obtain large independent (**not** approximately independent, but **exactly independent** samples with very low computational cost. See @WestHarr-DLM, chapter 15, for details about the sampling algorithm.

Our package offers the `dlm_sampling` function, which provides a routine for drawing independent samples from any fitted model:

```{r echo=TRUE, eval=FALSE}
dlm_sampling(fitted.data, 5000)
```


For the example above, where our model has $6$ latent states and $144$ observations (which yields a total of $864$ parameters), it takes approximately $0.3$ seconds to draw a sample of size $5.000$.

Another useful feature of our package is that it provides an approximate value for the Model likelihood $f(y)= \int_{\mathbb{R}^{n}}f(y|\theta)f(\theta)d\theta$, where $y$ represents the values for $Y_t$ for all $t$ and $\theta$ represents the values of $\theta_t$ for all $t$. This feature can be used for two main purposes: to compare different models and to evaluate the posterior distribution of hyper parameter. 

To compare different models, $\mathcal{M}_1,...,\mathcal{M}_k$ , one can note that $f(\mathcal{M}_i|y) \propto f(y|\mathcal{M}_i)f(\mathcal{M}_i)$, where $f(y|\mathcal{M}_i)= \int_{\mathbb{R}^{n}}f(y|\theta,\mathcal{M}_i)f(\theta|\mathcal{M}_i)d\theta$ is the likelihood of model $\mathcal{M}_i$ and $f(\mathcal{M}_i)$ is the prior for model $\mathcal{M}_i$. To evaluate $f(y|\mathcal{M}_i)$, one can make use of the `coef` method, the `eval_dlm_norm_const` function or `search_model` function by setting `lag` to a negative number (the log likelihood metric will be $\ln f(y|\mathcal{M}_i)$). Similarly, if the user wants to obtain the marginal posterior distribution of an hyper parameter $\tau$, it can observe that $f(\tau|y) \propto f(y|\tau)f(\tau)$, from which $f(y|\tau)$ can be evaluated using the `coef` method, the `eval_dlm_norm_const` function or `search_model` function.


```{r echo=TRUE}
H.range <- seq.int(0, 1, l = 100)
log.like.H <- seq_along(H.range)
log.prior.H <- dlnorm(H.range, 0, 1, log = TRUE)
for (i in seq_along(H.range)) {
  level <- polynomial_block(rate = 1, order = 2, H = H.range[i])
  season <- harmonic_block(rate = 1, order = 2, period = 12, D = 0.975)
  # Using only 10 observations, for the sake of a pretty plot. For this particular application, the posterior density of H rapidly becomes highly consentrated in a single value.
  outcome <- Poisson(lambda = "rate", data = c(AirPassengers)[1:20])
  fitted.data <- fit_model(level, season, outcome)
  log.like.H[i] <- eval_dlm_norm_const(fitted.data)
}
log.post.H <- log.prior.H + log.like.H
post.H <- exp(log.post.H - max(log.post.H))
plot(H.range, post.H, type = "l", xlab = "H", ylab = "f(H|y)")
```

# References

